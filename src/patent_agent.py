"""
Short-Cut v3.0 - Self-RAG Patent Agent with Hybrid Search & Streaming
==========================================================================
Advanced RAG pipeline with HyDE, Hybrid Search (RRF), Streaming, and CoT Analysis.

Features:
1. HyDE (Hypothetical Document Embedding) - Generate virtual claims for better retrieval
2. Hybrid Search - Dense (FAISS) + Sparse (BM25) with RRF fusion
3. LLM Streaming Response - Real-time analysis output
4. Critical CoT Analysis - Detailed similarity/infringement/avoidance analysis

Author: Team ë€¨ğŸ’•
License: MIT
"""

from __future__ import annotations

import asyncio
import logging
import os
from dataclasses import dataclass, field
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple, AsyncGenerator

from dotenv import load_dotenv
from pydantic import BaseModel, Field
from openai import AsyncOpenAI
import numpy as np

load_dotenv()

# Import orjson if available, otherwise fall back to json
try:
    import orjson
    def json_loads(s): return orjson.loads(s)
    def json_dumps(o): return orjson.dumps(o).decode()
except ImportError:
    import json
    json_loads = json.loads
    json_dumps = json.dumps

# =============================================================================
# Logging Setup
# =============================================================================

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# =============================================================================
# Configuration (Environment Variables)
# =============================================================================

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")

# Models - configurable via environment variables
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
GRADING_MODEL = os.environ.get("GRADING_MODEL", "gpt-4o-mini")  # Cost-effective
ANALYSIS_MODEL = os.environ.get("ANALYSIS_MODEL", "gpt-4o")  # High quality
HYDE_MODEL = os.environ.get("HYDE_MODEL", "gpt-4o-mini")

# Thresholds - configurable via environment variables
GRADING_THRESHOLD = float(os.environ.get("GRADING_THRESHOLD", "0.6"))
MAX_REWRITE_ATTEMPTS = int(os.environ.get("MAX_REWRITE_ATTEMPTS", "1"))
TOP_K_RESULTS = int(os.environ.get("TOP_K_RESULTS", "5"))

# Hybrid search weights
DENSE_WEIGHT = float(os.environ.get("DENSE_WEIGHT", "0.5"))
SPARSE_WEIGHT = float(os.environ.get("SPARSE_WEIGHT", "0.5"))

# Data paths - relative to this file
from pathlib import Path
DATA_DIR = Path(__file__).resolve().parent / "data"
PROCESSED_DIR = DATA_DIR / "processed"
OUTPUT_DIR = DATA_DIR / "outputs"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


# =============================================================================
# Pydantic Models for Structured Outputs
# =============================================================================

class GradingResult(BaseModel):
    """Structured grading result from GPT."""
    patent_id: str = Field(description="Patent publication number")
    score: float = Field(description="Relevance score from 0.0 to 1.0")
    reason: str = Field(description="Brief explanation for the score")


class GradingResponse(BaseModel):
    """Response containing all grading results."""
    results: List[GradingResult] = Field(description="List of grading results")
    average_score: float = Field(description="Average score across all results")


class QueryRewriteResponse(BaseModel):
    """Optimized search query from GPT."""
    optimized_query: str = Field(description="Improved search query")
    keywords: List[str] = Field(description="Key technical terms to search")
    reasoning: str = Field(description="Why this query should work better")


class SimilarityAnalysis(BaseModel):
    """ìœ ì‚¬ë„ í‰ê°€ section."""
    score: int = Field(description="Technical similarity score 0-100")
    common_elements: List[str] = Field(description="Shared technical elements")
    summary: str = Field(description="Overall similarity assessment")
    evidence_patents: List[str] = Field(description="Patent IDs supporting this analysis")


class InfringementAnalysis(BaseModel):
    """ì¹¨í•´ ë¦¬ìŠ¤í¬ section."""
    risk_level: str = Field(description="high, medium, or low")
    risk_factors: List[str] = Field(description="Specific infringement concerns")
    summary: str = Field(description="Overall risk assessment")
    evidence_patents: List[str] = Field(description="Patent IDs supporting this analysis")


class AvoidanceStrategy(BaseModel):
    """íšŒí”¼ ì „ëµ section."""
    strategies: List[str] = Field(description="Design-around approaches")
    alternative_technologies: List[str] = Field(description="Alternative implementations")
    summary: str = Field(description="Recommended avoidance approach")
    evidence_patents: List[str] = Field(description="Patent IDs informing these strategies")


class ComponentComparison(BaseModel):
    """êµ¬ì„±ìš”ì†Œ ëŒ€ë¹„í‘œ - Element-by-element comparison."""
    idea_components: List[str] = Field(description="User idea's key technical components")
    matched_components: List[str] = Field(description="Components found in prior patents")
    unmatched_components: List[str] = Field(description="Novel components not in prior art")
    risk_components: List[str] = Field(description="Components causing infringement risk")


class CriticalAnalysisResponse(BaseModel):
    """Complete critical analysis response."""
    similarity: SimilarityAnalysis
    infringement: InfringementAnalysis
    avoidance: AvoidanceStrategy
    component_comparison: ComponentComparison = Field(description="Element comparison table")
    conclusion: str = Field(description="Final recommendation")


# =============================================================================
# Patent Search Result
# =============================================================================

@dataclass
class PatentSearchResult:
    """A single patent search result."""
    publication_number: str
    title: str
    abstract: str
    claims: str
    ipc_codes: List[str]
    similarity_score: float = 0.0  # Vector similarity
    grading_score: float = 0.0  # LLM grading score
    grading_reason: str = ""
    
    # Hybrid search scores
    dense_score: float = 0.0
    sparse_score: float = 0.0
    rrf_score: float = 0.0


# =============================================================================
# Patent Agent - Main Class
# =============================================================================

class PatentAgent:
    """
    Self-RAG Patent Analysis Agent (v3.0).
    
    Features:
    - FAISS + BM25 hybrid search with RRF fusion
    - OpenAI API for embeddings and LLM
    - Streaming response for real-time analysis
    
    Implements:
    1. HyDE - Hypothetical Document Embedding
    2. Hybrid Search - Dense + Sparse with RRF
    3. Grading & Rewrite Loop
    4. Critical CoT Analysis with Streaming
    """
    
    def __init__(self, db_client=None):
        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY not set. Check .env file.")
        
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        
        # Initialize Vector DB client with hybrid search
        if db_client is not None:
            self.db_client = db_client
        else:
            # Use PineconeClient for v3.0 Migration
            from vector_db import PineconeClient
            self.db_client = PineconeClient()
            self._try_load_local_cache()
    
    def _try_load_local_cache(self) -> bool:
        """Try to load local metadata cache and BM25 index."""
        loaded = self.db_client.load_local()
        if loaded:
            stats = self.db_client.get_stats()
            logger.info(f"Loaded local cache: {stats.get('bm25_docs', 0)} docs in BM25")
            return True
        else:
            logger.warning("No local cache found. Run pipeline to build BM25 index.")
            return False
    
    def index_loaded(self) -> bool:
        """Check if DB is ready."""
        # For Pinecone, we assume it's always ready if initialized
        return True
    
    # =========================================================================
    # Keyword Extraction for Hybrid Search
    # =========================================================================
    
    async def extract_keywords(self, text: str) -> List[str]:
        """
        Extract keywords from text for BM25 search.
        Uses both rule-based extraction and optional LLM enhancement.
        """
        from vector_db import KeywordExtractor
        
        # Rule-based extraction
        keywords = KeywordExtractor.extract(text, max_keywords=15)
        
        return keywords
    
    # =========================================================================
    # 1. HyDE - Hypothetical Document Embedding
    # =========================================================================
    
    async def generate_hypothetical_claim(self, user_idea: str) -> str:
        """
        Generate a hypothetical patent claim from user's idea.
        """
        system_prompt = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ë² í…Œë‘ íŠ¹í—ˆ ë³€ë¦¬ì‚¬ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ ê¸°ìˆ ì´ íŠ¹í—ˆë¡œ ì¶œì›ë˜ì—ˆì„ ë•Œì˜ 'ì œ1í•­(ë…ë¦½í•­)'ì„ ê°€ìƒìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

ì‘ì„± ê°€ì´ë“œë¼ì¸:
1. ì „ë¬¸ ìš©ì–´ ì‚¬ìš©: 'ë°ì´í„°ë² ì´ìŠ¤' ëŒ€ì‹  'ë²¡í„° ìƒ‰ì¸ ë°ì´í„° êµ¬ì¡°', 'ì°¾ê¸°' ëŒ€ì‹  'ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰' ë“± ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
2. êµ¬ì¡°í™”: [ì „ì œë¶€] - [êµ¬ì„±ìš”ì†Œ 1] - [êµ¬ì„±ìš”ì†Œ 2] - [ê¸°ëŠ¥ì  ìœ ê¸°ì  ê²°í•© ê´€ê³„] ìˆœìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
3. í˜•ì‹: "~ë¥¼ íŠ¹ì§•ìœ¼ë¡œ í•˜ëŠ” [ê¸°ìˆ  ëª…ì¹­]"ê³¼ ê°™ì€ íŠ¹í—ˆ íŠ¹ìœ ì˜ ë¬¸ì²´ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.

ì´ ê°€ìƒ ì²­êµ¬í•­ì€ ì‹¤ì œ íŠ¹í—ˆ ë°ì´í„°ì…‹ì—ì„œ ìœ ì‚¬í•œ ê¸°ìˆ ì„ ì°¾ì•„ë‚´ê¸° ìœ„í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤."""

        user_prompt = f"ì•„ì´ë””ì–´: {user_idea}\n\nìœ„ ì•„ì´ë””ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì „ë¬¸ì ì¸ ê°€ìƒ ì œ1í•­(ë…ë¦½í•­)ì„ ì‘ì„±í•˜ì‹­ì‹œì˜¤."

        response = await self.client.chat.completions.create(
            model=HYDE_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=500,
        )
        
        hypothetical_claim = response.choices[0].message.content.strip()
        logger.info(f"Generated hypothetical claim: {hypothetical_claim[:100]}...")
        
        return hypothetical_claim
    
    async def embed_text(self, text: str) -> np.ndarray:
        """Generate embedding using OpenAI text-embedding-3-small."""
        response = await self.client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=text,
        )
        return np.array(response.data[0].embedding, dtype=np.float32)
    
    async def hyde_search(
        self,
        user_idea: str,
        top_k: int = TOP_K_RESULTS,
        use_hybrid: bool = True,
    ) -> Tuple[str, List[PatentSearchResult]]:
        """
        HyDE-enhanced patent search with optional hybrid search.
        
        1. Generate hypothetical claim from user idea
        2. Embed the hypothetical claim
        3. Search using hybrid (dense + sparse) or dense only
        
        Returns:
            Tuple of (hypothetical_claim, search_results)
        """
        # Generate hypothetical claim
        hypothetical_claim = await self.generate_hypothetical_claim(user_idea)
        
        # Check if index is available
        if not self.index_loaded():
            logger.warning("Index not loaded. Returning empty results.")
            return hypothetical_claim, []
        
        # Embed the hypothetical claim
        query_embedding = await self.embed_text(hypothetical_claim)
        
        # Extract keywords for hybrid search
        keywords = await self.extract_keywords(user_idea + " " + hypothetical_claim)
        query_text = " ".join(keywords)
        
        # Search
        if use_hybrid:
            search_results = await self.db_client.async_hybrid_search(
                query_embedding,
                query_text,
                top_k=top_k,
                dense_weight=DENSE_WEIGHT,
                sparse_weight=SPARSE_WEIGHT,
            )
        else:
            search_results = await self.db_client.async_search(query_embedding, top_k=top_k)
        
        # Convert to PatentSearchResult
        results = []
        for r in search_results:
            results.append(PatentSearchResult(
                publication_number=r.patent_id,
                title=r.metadata.get("title", ""),
                abstract=r.metadata.get("abstract", r.content[:500]),
                claims=r.metadata.get("claims", ""),
                ipc_codes=[r.metadata.get("ipc_code", "")] if r.metadata.get("ipc_code") else [],
                similarity_score=r.score,
                dense_score=getattr(r, 'dense_score', 0.0),
                sparse_score=getattr(r, 'sparse_score', 0.0),
                rrf_score=getattr(r, 'rrf_score', 0.0),
            ))
        
        if results:
            logger.info(f"Hybrid search found {len(results)} results (top RRF score: {results[0].rrf_score:.4f})")
        else:
            logger.info("No results found")
        
        return hypothetical_claim, results
    
    # =========================================================================
    # 2. Grading & Rewrite Loop
    # =========================================================================
    
    async def grade_results(
        self,
        user_idea: str,
        results: List[PatentSearchResult],
    ) -> GradingResponse:
        """Grade each search result for relevance to user's idea."""
        if not results:
            return GradingResponse(results=[], average_score=0.0)
        
        results_text = "\n\n".join([
            f"[íŠ¹í—ˆ {i+1}: {r.publication_number}]\n"
            f"ì œëª©: {r.title}\n"
            f"ì´ˆë¡: {r.abstract[:300]}...\n"
            f"ì²­êµ¬í•­: {r.claims[:300]}..."
            for i, r in enumerate(results)
        ])
        
        system_prompt = """ë‹¹ì‹ ì€ ì„ í–‰ ê¸°ìˆ  ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” íŠ¹í—ˆ ì‹¬ì‚¬ê´€ì…ë‹ˆë‹¤.
ê²€ìƒ‰ëœ íŠ¹í—ˆê°€ ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ì™€ ê¸°ìˆ ì ìœ¼ë¡œ ì‹¤ì§ˆì ì¸ ê´€ë ¨ì´ ìˆëŠ”ì§€ í‰ê°€í•˜ì‹­ì‹œì˜¤.

í‰ê°€ ê¸°ì¤€ (0.0 ~ 1.0 ì ):
1. ê¸°ìˆ  ë¶„ì•¼ ì¼ì¹˜ì„±
2. í•´ê²° ìˆ˜ë‹¨ ìœ ì‚¬ì„±
3. ì¹¨í•´ ë¶„ì„ ê°€ì¹˜

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤."""

        user_prompt = f"""[ì‚¬ìš©ì ì•„ì´ë””ì–´]
{user_idea}

[ê²€ìƒ‰ëœ íŠ¹í—ˆ ëª©ë¡]
{results_text}

ê° íŠ¹í—ˆì— ëŒ€í•´ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ í‰ê°€í•˜ì‹­ì‹œì˜¤:
{{
  "results": [
    {{"patent_id": "íŠ¹í—ˆë²ˆí˜¸", "score": 0.0-1.0, "reason": "í‰ê°€ ì´ìœ "}}
  ],
  "average_score": ì „ì²´í‰ê· ì ìˆ˜
}}"""

        response = await self.client.chat.completions.create(
            model=GRADING_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.1,
        )
        
        try:
            grading_data = json_loads(response.choices[0].message.content)
            grading_response = GradingResponse(**grading_data)
            
            for grade in grading_response.results:
                for result in results:
                    if result.publication_number == grade.patent_id:
                        result.grading_score = grade.score
                        result.grading_reason = grade.reason
            
            return grading_response
            
        except Exception as e:
            logger.error(f"Failed to parse grading response: {e}")
            return GradingResponse(results=[], average_score=0.0)
    
    async def rewrite_query(
        self,
        user_idea: str,
        previous_results: List[PatentSearchResult],
    ) -> QueryRewriteResponse:
        """Optimize search query based on poor results."""
        results_summary = "\n".join([
            f"- {r.publication_number}: score={r.grading_score:.2f}, {r.grading_reason}"
            for r in previous_results
        ])
        
        prompt = f"""ê²€ìƒ‰ ê²°ê³¼ê°€ ê´€ë ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìµœì í™”í•´ì£¼ì„¸ìš”.

[ì›ë˜ ì•„ì´ë””ì–´]
{user_idea}

[ì´ì „ ê²€ìƒ‰ ê²°ê³¼ (ë‚®ì€ ì ìˆ˜)]
{results_summary}

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
  "optimized_query": "ê°œì„ ëœ ê²€ìƒ‰ ì¿¼ë¦¬",
  "keywords": ["í•µì‹¬", "ê¸°ìˆ ", "í‚¤ì›Œë“œ"],
  "reasoning": "ê°œì„  ì´ìœ "
}}"""

        response = await self.client.chat.completions.create(
            model=GRADING_MODEL,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.3,
        )
        
        try:
            data = json_loads(response.choices[0].message.content)
            return QueryRewriteResponse(**data)
        except Exception as e:
            logger.error(f"Failed to parse rewrite response: {e}")
            return QueryRewriteResponse(
                optimized_query=user_idea,
                keywords=[],
                reasoning="Failed to optimize"
            )
    
    async def search_with_grading(
        self,
        user_idea: str,
        use_hybrid: bool = True,
    ) -> List[PatentSearchResult]:
        """Complete search pipeline with grading and optional rewrite."""
        # Initial HyDE search
        hypothetical_claim, results = await self.hyde_search(user_idea, use_hybrid=use_hybrid)
        
        if not results:
            logger.warning("No search results found")
            return []
        
        # Grade results
        grading = await self.grade_results(user_idea, results)
        logger.info(f"Initial grading - Average score: {grading.average_score:.2f}")
        
        # Check if rewrite is needed
        if grading.average_score < GRADING_THRESHOLD:
            logger.info(f"Score below threshold ({GRADING_THRESHOLD}), attempting query rewrite...")
            
            rewrite = await self.rewrite_query(user_idea, results)
            logger.info(f"Rewritten query: {rewrite.optimized_query}")
            
            _, new_results = await self.hyde_search(rewrite.optimized_query, use_hybrid=use_hybrid)
            
            new_grading = await self.grade_results(user_idea, new_results)
            logger.info(f"After rewrite - Average score: {new_grading.average_score:.2f}")
            
            if new_grading.average_score > grading.average_score:
                results = new_results
                grading = new_grading
        
        results.sort(key=lambda x: x.grading_score, reverse=True)
        
        return results
    
    # =========================================================================
    # 3. Critical CoT Analysis - Standard (Non-Streaming)
    # =========================================================================
    
    async def critical_analysis(
        self,
        user_idea: str,
        results: List[PatentSearchResult],
    ) -> CriticalAnalysisResponse:
        """
        Perform critical Chain-of-Thought analysis (non-streaming).
        """
        if not results:
            return self._empty_analysis()
        
        patents_text = "\n\n".join([
            f"=== íŠ¹í—ˆ {r.publication_number} ===\n"
            f"ì œëª©: {r.title}\n"
            f"IPC: {', '.join(r.ipc_codes[:3])}\n"
            f"ì´ˆë¡: {r.abstract}\n"
            f"ì²­êµ¬í•­: {r.claims}\n"
            f"ê´€ë ¨ì„± ì ìˆ˜: {r.grading_score:.2f} ({r.grading_reason})"
            for r in results[:5]
        ])
        
        system_prompt, user_prompt = self._build_analysis_prompts(user_idea, patents_text)
        
        response = await self.client.chat.completions.create(
            model=ANALYSIS_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.2,
            max_tokens=2500,
        )
        
        try:
            data = json_loads(response.choices[0].message.content)
            return CriticalAnalysisResponse(**data)
        except Exception as e:
            logger.error(f"Failed to parse analysis response: {e}")
            return self._empty_analysis()
    
    # =========================================================================
    # 4. Critical CoT Analysis - Streaming
    # =========================================================================
    
    async def critical_analysis_stream(
        self,
        user_idea: str,
        results: List[PatentSearchResult],
    ) -> AsyncGenerator[str, None]:
        """
        Perform critical Chain-of-Thought analysis with streaming.
        
        Yields:
            Tokens as they are generated by the LLM
        """
        if not results:
            yield "ë¶„ì„í•  íŠ¹í—ˆê°€ ì—†ìŠµë‹ˆë‹¤."
            return
        
        patents_text = "\n\n".join([
            f"=== íŠ¹í—ˆ {r.publication_number} ===\n"
            f"ì œëª©: {r.title}\n"
            f"IPC: {', '.join(r.ipc_codes[:3])}\n"
            f"ì´ˆë¡: {r.abstract[:500]}\n"
            f"ì²­êµ¬í•­: {r.claims[:500]}\n"
            f"ê´€ë ¨ì„± ì ìˆ˜: {r.grading_score:.2f}"
            for r in results[:5]
        ])
        
        system_prompt = """ë‹¹ì‹ ì€ íŠ¹í—ˆ ë¶„ìŸ ëŒ€ì‘ ì „ë¬¸ ë³€ë¦¬ì‚¬ì…ë‹ˆë‹¤. 
ì œê³µëœ ì„ í–‰ íŠ¹í—ˆ(Context)ì™€ ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ ëŒ€ë¹„ ë¶„ì„í•˜ì—¬ ì „ëµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

**ì¤‘ìš”**: ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‹¤ì‹œê°„ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

ë¶„ì„ ì›ì¹™:
1. êµ¬ì„±ìš”ì†Œ ëŒ€ë¹„ ë¶„ì„: ì‚¬ìš©ìì˜ ê¸°ìˆ ì´ ì„ í–‰ íŠ¹í—ˆ ì²­êµ¬í•­ì˜ ëª¨ë“  êµ¬ì„±ìš”ì†Œë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
2. ì¹¨í•´ ë¦¬ìŠ¤í¬ íŒì •: High/Medium/Lowë¡œ êµ¬ë¶„
3. íšŒí”¼ ì „ëµ: ì¹¨í•´ë¥¼ í”¼í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ê¸°ìˆ  ë³€ê²½ ì œì•ˆ

ì¶œë ¥ í˜•ì‹ (ë§ˆí¬ë‹¤ìš´):
## 1. ìœ ì‚¬ë„ í‰ê°€
(ì ìˆ˜ ë° ë¶„ì„)

## 2. ì¹¨í•´ ë¦¬ìŠ¤í¬
(ìœ„í—˜ ìˆ˜ì¤€ ë° ìš”ì†Œ)

## 3. íšŒí”¼ ì „ëµ
(êµ¬ì²´ì  ì „ëµ)

## 4. ê²°ë¡ 
(ìµœì¢… ê¶Œê³ )"""

        user_prompt = f"""[ë¶„ì„ ëŒ€ìƒ: ì‚¬ìš©ì ì•„ì´ë””ì–´]
{user_idea}

[ì°¸ì¡° íŠ¹í—ˆ ëª©ë¡ (ì„ í–‰ ê¸°ìˆ )]
{patents_text}

ìœ„ ì„ í–‰ íŠ¹í—ˆë“¤ê³¼ ì‚¬ìš©ì ì•„ì´ë””ì–´ë¥¼ ëŒ€ë¹„ ë¶„ì„í•˜ì—¬ ì „ëµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤."""

        response = await self.client.chat.completions.create(
            model=ANALYSIS_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            stream=True,
            temperature=0.2,
            max_tokens=2500,
        )
        
        async for chunk in response:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
    
    def _build_analysis_prompts(self, user_idea: str, patents_text: str) -> Tuple[str, str]:
        """Build system and user prompts for analysis."""
        system_prompt = """ë‹¹ì‹ ì€ íŠ¹í—ˆ ë¶„ìŸ ëŒ€ì‘ ì „ë¬¸ ë³€ë¦¬ì‚¬ì…ë‹ˆë‹¤. 
ì œê³µëœ ì„ í–‰ íŠ¹í—ˆ(Context)ì™€ ì‚¬ìš©ìì˜ ì•„ì´ë””ì–´ë¥¼ ëŒ€ë¹„ ë¶„ì„í•˜ì—¬ ì „ëµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

ë¶„ì„ ì›ì¹™:
1. êµ¬ì„±ìš”ì†Œ ëŒ€ë¹„ ë¶„ì„: ì‚¬ìš©ìì˜ ê¸°ìˆ ì´ ì„ í–‰ íŠ¹í—ˆ ì²­êµ¬í•­ì˜ ëª¨ë“  êµ¬ì„±ìš”ì†Œë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
2. ì¹¨í•´ ë¦¬ìŠ¤í¬ íŒì •: High/Medium/Low
3. íšŒí”¼ ì „ëµ: ì‚­ì œ, ë³€ê²½, ì¶”ê°€í•´ì•¼ í•  ê¸°ìˆ ì  ìš”ì†Œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œ

ë°˜ë“œì‹œ ê° ë¶„ì„ì— ê·¼ê±°ê°€ ëœ íŠ¹í—ˆ ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì‹­ì‹œì˜¤."""

        user_prompt = f"""[ë¶„ì„ ëŒ€ìƒ: ì‚¬ìš©ì ì•„ì´ë””ì–´]
{user_idea}

[ì°¸ì¡° íŠ¹í—ˆ ëª©ë¡ (ì„ í–‰ ê¸°ìˆ )]
{patents_text}

ìœ„ ì„ í–‰ íŠ¹í—ˆë“¤ê³¼ ì‚¬ìš©ì ì•„ì´ë””ì–´ë¥¼ ëŒ€ë¹„ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤:
{{
  "similarity": {{
    "score": 0-100,
    "common_elements": ["ê³µí†µ êµ¬ì„±ìš”ì†Œ"],
    "summary": "ë¶„ì„ ê²°ê³¼",
    "evidence_patents": ["íŠ¹í—ˆë²ˆí˜¸"]
  }},
  "infringement": {{
    "risk_level": "high/medium/low",
    "risk_factors": ["ìœ„í—˜ ìš”ì†Œ"],
    "summary": "ë¦¬ìŠ¤í¬ í‰ê°€",
    "evidence_patents": ["íŠ¹í—ˆë²ˆí˜¸"]
  }},
  "avoidance": {{
    "strategies": ["íšŒí”¼ ì „ëµ"],
    "alternative_technologies": ["ëŒ€ì•ˆ ê¸°ìˆ "],
    "summary": "íšŒí”¼ ê¶Œê³ ",
    "evidence_patents": ["íŠ¹í—ˆë²ˆí˜¸"]
  }},
  "component_comparison": {{
    "idea_components": ["ì•„ì´ë””ì–´ êµ¬ì„±ìš”ì†Œ"],
    "matched_components": ["ì¼ì¹˜ êµ¬ì„±ìš”ì†Œ"],
    "unmatched_components": ["ì‹ ê·œ êµ¬ì„±ìš”ì†Œ"],
    "risk_components": ["ìœ„í—˜ êµ¬ì„±ìš”ì†Œ"]
  }},
  "conclusion": "ìµœì¢… ê¶Œê³ "
}}"""
        
        return system_prompt, user_prompt
    
    def _empty_analysis(self) -> CriticalAnalysisResponse:
        """Return empty analysis when no results."""
        return CriticalAnalysisResponse(
            similarity=SimilarityAnalysis(
                score=0,
                common_elements=[],
                summary="ë¶„ì„í•  íŠ¹í—ˆê°€ ì—†ìŠµë‹ˆë‹¤.",
                evidence_patents=[]
            ),
            infringement=InfringementAnalysis(
                risk_level="unknown",
                risk_factors=[],
                summary="ë¶„ì„í•  íŠ¹í—ˆê°€ ì—†ìŠµë‹ˆë‹¤.",
                evidence_patents=[]
            ),
            avoidance=AvoidanceStrategy(
                strategies=[],
                alternative_technologies=[],
                summary="ë¶„ì„í•  íŠ¹í—ˆê°€ ì—†ìŠµë‹ˆë‹¤.",
                evidence_patents=[]
            ),
            component_comparison=ComponentComparison(
                idea_components=[],
                matched_components=[],
                unmatched_components=[],
                risk_components=[]
            ),
            conclusion="ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    # =========================================================================
    # Main Pipeline
    # =========================================================================
    
    async def analyze(
        self,
        user_idea: str,
        use_hybrid: bool = True,
        stream: bool = False,
    ) -> Dict[str, Any]:
        """
        Complete Self-RAG pipeline.
        
        Args:
            user_idea: User's patent idea
            use_hybrid: Use hybrid search (dense + sparse)
            stream: Stream analysis output (not applicable for dict output)
        """
        print("\n" + "=" * 70)
        print("âš¡ ì‡¼íŠ¹í—ˆ (Short-Cut) v3.0 - Self-RAG Analysis (Hybrid + Streaming)")
        print("=" * 70)
        
        print(f"\nğŸ“ User Idea: {user_idea[:100]}...")
        
        print("\nğŸ” Step 1-2: HyDE + Hybrid Search & Grading...")
        results = await self.search_with_grading(user_idea, use_hybrid=use_hybrid)
        
        if not results:
            return {"error": "No relevant patents found"}
        
        print(f"   Found {len(results)} relevant patents")
        for r in results[:3]:
            print(f"   - {r.publication_number}: {r.grading_score:.2f} (RRF: {r.rrf_score:.4f})")
        
        print("\nğŸ§  Step 3: Critical CoT Analysis...")
        analysis = await self.critical_analysis(user_idea, results)
        
        output = {
            "user_idea": user_idea,
            "search_results": [
                {
                    "patent_id": r.publication_number,
                    "title": r.title,
                    "abstract": r.abstract,  # Added for DeepEval Faithfulness
                    "claims": r.claims,      # Added for DeepEval Faithfulness
                    "grading_score": r.grading_score,
                    "grading_reason": r.grading_reason,
                    "dense_score": r.dense_score,
                    "sparse_score": r.sparse_score,
                    "rrf_score": r.rrf_score,
                }
                for r in results
            ],
            "analysis": {
                "similarity": {
                    "score": analysis.similarity.score,
                    "common_elements": analysis.similarity.common_elements,
                    "summary": analysis.similarity.summary,
                    "evidence": analysis.similarity.evidence_patents,
                },
                "infringement": {
                    "risk_level": analysis.infringement.risk_level,
                    "risk_factors": analysis.infringement.risk_factors,
                    "summary": analysis.infringement.summary,
                    "evidence": analysis.infringement.evidence_patents,
                },
                "avoidance": {
                    "strategies": analysis.avoidance.strategies,
                    "alternatives": analysis.avoidance.alternative_technologies,
                    "summary": analysis.avoidance.summary,
                    "evidence": analysis.avoidance.evidence_patents,
                },
                "conclusion": analysis.conclusion,
            },
            "timestamp": datetime.now().isoformat(),
            "search_type": "hybrid" if use_hybrid else "dense",
        }
        
        print("\n" + "=" * 70)
        print("ğŸ“Š Analysis Complete!")
        print("=" * 70)
        print(f"\n[ìœ ì‚¬ë„ í‰ê°€] Score: {analysis.similarity.score}/100")
        print(f"\n[ì¹¨í•´ ë¦¬ìŠ¤í¬] Level: {analysis.infringement.risk_level.upper()}")
        print(f"\nğŸ“Œ Conclusion: {analysis.conclusion[:150]}...")
        
        return output


# =============================================================================
# CLI Entry Point
# =============================================================================

async def main():
    """Interactive CLI for patent analysis."""
    print("\n" + "=" * 70)
    print("âš¡ ì‡¼íŠ¹í—ˆ (Short-Cut) v3.0 - Self-RAG Patent Agent")
    print("    Hybrid Search + Streaming Edition")
    print("=" * 70)
    print("\níŠ¹í—ˆ ë¶„ì„ì„ ìœ„í•œ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    agent = PatentAgent()
    
    if not agent.index_loaded():
        print("âš ï¸  Index not found. Please run the pipeline first:")
        print("   python pipeline.py --stage 5\n")
    
    while True:
        try:
            user_input = input("\nğŸ’¡ Your idea: ").strip()
            
            if user_input.lower() in ['exit', 'quit', 'q']:
                print("ğŸ‘‹ Goodbye!")
                break
            
            if not user_input:
                print("âŒ Please enter an idea.")
                continue
            
            result = await agent.analyze(user_input, use_hybrid=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = OUTPUT_DIR / f"analysis_{timestamp}.json"
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(json_dumps(result))
            
            print(f"\nğŸ’¾ Result saved to: {output_path}")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")


if __name__ == "__main__":
    asyncio.run(main())
